import asyncio
import json
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple

from app import config

# ---------- Optional Gemini ----------
try:
    import google.generativeai as genai  # type: ignore

    _GEMINI_AVAILABLE = True
except Exception as e:
    print("[LLM] ‚ö†Ô∏è Google GenerativeAI SDK not found:", e)
    genai = None
    _GEMINI_AVAILABLE = False


# ==============================
# Heuristic (Rule-based)
# ==============================
class HeuristicAnalyzer:
    """Rule-based scoring 0..100 cho lead."""

    def score_lead(self, lead: Dict[str, Any]) -> Tuple[int, str]:
        score = 0
        reasons: List[str] = []

        source = (lead.get("source") or "").lower()
        if source in ("referral", "partner"):
            score += 25
            reasons.append(f"source={source}+25")
        elif source in ("ads", "website"):
            score += 10
            reasons.append(f"source={source}+10")

        status = (lead.get("status") or "").lower()
        if status == "engaged":
            score += 20
            reasons.append("status=engaged+20")
        elif status == "new":
            score += 5
            reasons.append("status=new+5")

        if lead.get("email"):
            score += 10
            reasons.append("email+10")
        if lead.get("phone"):
            score += 10
            reasons.append("phone+10")

        interactions = lead.get("interactions") or []
        page_views = sum(1 for it in interactions if it.get("type") == "page_view")
        email_clicks = sum(1 for it in interactions if it.get("type") == "email_click")
        if page_views:
            add = min(page_views * 2, 10)
            score += add
            reasons.append(f"page_views*2={add}")
        if email_clicks:
            add = min(email_clicks * 5, 20)
            score += add
            reasons.append(f"email_clicks*5={add}")

        score = max(0, min(score, 100))
        return score, "; ".join(reasons) if reasons else "baseline"


# ==============================
# Hybrid Scorer (LLM + Fallback)
# ==============================
class HybridLeadScorer:
    """
    G·ªçi LLM ƒë·ªÉ ch·∫•m lead (fit_score + intent score + d·ª± b√°o) theo schema chu·∫©n.
    Fallback v·ªÅ HeuristicAnalyzer n·∫øu LLM t·∫Øt ho·∫∑c tr·∫£ k·∫øt qu·∫£ kh√¥ng h·ª£p l·ªá.
    """

    def __init__(self, llm_service: "LLMService", heuristic: Optional[HeuristicAnalyzer] = None):
        self.llm = llm_service
        self.heur = heuristic or HeuristicAnalyzer()

    async def score(self, lead: Dict[str, Any]) -> Dict[str, Any]:
        """
        Tr·∫£ v·ªÅ dict:
        { fit_score, score, priority_suggestion, predicted_prob,
          predicted_value, predicted_value_currency, reason, confidence,
          features_used, next_best_action }
        """
        # ---- LLM mode ----
        if getattr(self.llm, "enabled", False):
            prompt = self._build_prompt(lead)
            raw = await self.llm._generate(prompt, model=self.llm.model_scoring)
            data = _parse_json_only(raw)
            if data is not None:
                return self._coerce_schema(data, lead)
            # n·∫øu LLM tr·∫£ kh√¥ng h·ª£p l·ªá -> fallback

        # ---- Fallback Heuristic ----
        score, reason = self.heur.score_lead(lead)
        fit_score = 70 if (lead.get("source") or "").lower() in ("referral", "partner") else 45
        predicted_prob = round(min(0.8, max(0.05, 0.4 * score / 100 + 0.6 * fit_score / 100)), 3)
        return {
            "fit_score": int(max(0, min(100, fit_score))),
            "score": int(score),
            "priority_suggestion": self._priority_from_score(score),
            "predicted_prob": float(predicted_prob),
            "predicted_value": 0.0,
            "predicted_value_currency": "VND",
            "reason": reason or "baseline",
            "confidence": 0.5,
            "features_used": {},
            "next_best_action": "follow_up",
        }

    # ---------- helpers ----------
    def _priority_from_score(self, s: float) -> str:
        s = float(s or 0)
        if s >= 80:
            return "urgent"
        if s >= 60:
            return "high"
        if s >= 30:
            return "medium"
        return "low"

    def _coerce_schema(self, d: Dict[str, Any], lead: Dict[str, Any]) -> Dict[str, Any]:
        def num(x, fb=0.0):
            try:
                return float(x)
            except Exception:
                return fb

        out = {
            "fit_score": int(max(0, min(100, num(d.get("fit_score"), 0)))),
            "score": int(max(0, min(100, num(d.get("score"), 0)))),
            "priority_suggestion": (d.get("priority_suggestion") or "").lower() or "medium",
            "predicted_prob": float(max(0.0, min(1.0, num(d.get("predicted_prob"), 0.2)))),
            "predicted_value": float(max(0.0, num(d.get("predicted_value"), 0.0))),
            "predicted_value_currency": d.get("predicted_value_currency") or "VND",
            "reason": d.get("reason") or "",
            "confidence": float(max(0.0, min(1.0, num(d.get("confidence"), 0.6)))),
            "features_used": d.get("features_used")
            or {
                "source": (lead.get("source") or "").lower(),
                "email_domain": ((lead.get("email") or "").split("@")[-1] if lead.get("email") else None),
            },
            "next_best_action": d.get("next_best_action") or None,
        }
        if out["priority_suggestion"] not in ("low", "medium", "high", "urgent"):
            out["priority_suggestion"] = self._priority_from_score(out["score"])
        return out

    def _build_prompt(self, lead: Dict[str, Any]) -> str:
        schema = {
            "fit_score": 70,
            "score": 55,
            "priority_suggestion": "high",
            "predicted_prob": 0.35,
            "predicted_value": 500000,
            "predicted_value_currency": "VND",
            "reason": "ngu·ªìn referral, c√≥ email/phone, ƒë√£ click email",
            "confidence": 0.7,
            "features_used": {"source": (lead.get("source") or "").lower()},
            "next_best_action": "call_back",
        }
        parts: List[str] = []
        parts.append(
            "B·∫°n l√† h·ªá th·ªëng ch·∫•m ƒëi·ªÉm lead cho CRM m·ªπ ph·∫©m. "
            "H√£y ph√¢n t√≠ch lead v√† tr·∫£ v·ªÅ M·ªòT ƒë·ªëi t∆∞·ª£ng JSON **h·ª£p l·ªá** theo schema sau (kh√¥ng th√™m ch·ªØ n√†o ngo√†i JSON)."
        )
        parts.append("Lead JSON:")
        parts.append(json.dumps(lead, ensure_ascii=False, indent=2))
        parts.append("Schema m·∫´u (gi√° tr·ªã minh h·ªça, h√£y thay b·∫±ng k·∫øt qu·∫£ c·ªßa b·∫°n):")
        parts.append(json.dumps(schema, ensure_ascii=False, indent=2))
        parts.append(
            "Y√äU C·∫¶U:\n"
            "- fit_score v√† score ‚àà [0,100]\n"
            "- predicted_prob ‚àà [0,1]\n"
            "- priority_suggestion ‚àà {'low','medium','high','urgent'}\n"
            "- Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng markdown, kh√¥ng gi·∫£i th√≠ch."
        )
        return "\n\n".join(parts)


# ==============================
# LLM Service (public API)
# ==============================
class LLMService:
    def __init__(self):
        self.enabled = bool(getattr(config, "GEMINI_API_KEY", None) and _GEMINI_AVAILABLE)
        self.model_scoring = getattr(
            config, "GEMINI_MODEL_SCORING", getattr(config, "GEMINI_MODEL_GENERIC", "gemini-1.5-flash")
        )

        if self.enabled:
            print("[LLM] ‚úÖ Gemini enabled with model:", self.model_scoring)
            genai.configure(api_key=config.GEMINI_API_KEY)  # type: ignore
        else:
            print("[LLM] ‚ö†Ô∏è Gemini disabled (missing API key or SDK).")

        self.scorer = HybridLeadScorer(self)

    async def score_lead(self, lead: Dict[str, Any]) -> Dict[str, Any]:
        """ƒêi·ªÉm v√†o ch√≠nh ƒë·ªÉ Node g·ªçi: tr·∫£ v·ªÅ schema th·ªëng nh·∫•t."""
        return await self.scorer.score(lead)

    # ----------------- Generate Email -----------------
    async def generate_email_content(
        self,
        context: Dict[str, Any],
        purpose: str = "promotion",
        options: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, str]:
        """Sinh n·ªôi dung email g·ªìm {subject, body} d·ª±a tr√™n ng·ªØ c·∫£nh action."""
        if not self.enabled:
            return {
                "subject": f"[{context.get('campaign', 'Th√¥ng b√°o')}] {context.get('product', 'S·∫£n ph·∫©m m·ªõi')} c·ªßa b·∫°n",
                "body": (
                    f"Xin ch√†o {context.get('name', 'b·∫°n')},\n\n"
                    f"Ch√∫ng t√¥i xin gi·ªõi thi·ªáu {context.get('product', 's·∫£n ph·∫©m m·ªõi')}."
                    f" H√£y gh√© c·ª≠a h√†ng ƒë·ªÉ nh·∫≠n ∆∞u ƒë√£i {context.get('offer', 'ƒë·∫∑c bi·ªát')}!\n\n"
                    "Th√¢n m·∫øn,\nƒê·ªôi ng≈© chƒÉm s√≥c kh√°ch h√†ng."
                ),
            }

        prompt = (
            "B·∫°n l√† chuy√™n gia marketing trong lƒ©nh v·ª±c m·ªπ ph·∫©m. "
            "H√£y so·∫°n **email** b·∫±ng ti·∫øng Vi·ªát ph√π h·ª£p v·ªõi m·ª•c ƒë√≠ch d∆∞·ªõi ƒë√¢y.\n\n"
            f"- M·ª•c ƒë√≠ch: {purpose}\n"
            "- Y√™u c·∫ßu:\n"
            "  ‚Ä¢ Vi·∫øt ng·∫Øn g·ªçn, t·ª± nhi√™n, ph√π h·ª£p kh√°ch h√†ng B2C.\n"
            "  ‚Ä¢ Tr·∫£ v·ªÅ **JSON h·ª£p l·ªá** d·∫°ng:\n"
            '    {"subject": "<ti√™u ƒë·ªÅ>", "body": "<n·ªôi dung email>"}.\n'
            "  ‚Ä¢ Kh√¥ng vi·∫øt ngo√†i JSON.\n\n"
            f"Ng·ªØ c·∫£nh action:\n{json.dumps(context, ensure_ascii=False, indent=2)}"
        )

        raw = await self._generate(prompt, model=getattr(config, "GEMINI_MODEL_GENERIC", self.model_scoring))
        data = _parse_json_only(raw)
        if isinstance(data, dict) and "subject" in data and "body" in data:
            return data

        subj = f"Khuy·∫øn m√£i: {context.get('product', 'S·∫£n ph·∫©m m·ªõi')} ƒëang gi·∫£m gi√°!"
        return {"subject": subj, "body": (raw or "").strip()[:1000]}

    # ----------------- Campaign Suggestion -----------------
    async def suggest_marketing_campaign(
        self,
        customer_data: List[Dict[str, Any]],
        product_data: Optional[List[Dict[str, Any]]] ,
        topic: Optional[str] = None,
        options: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        ƒê·ªÅ xu·∫•t 1 chi·∫øn d·ªãch marketing chi ti·∫øt (JSON h·ª£p l·ªá).
        Tr·∫£ v·ªÅ dict c√≥ c√°c tr∆∞·ªùng: name, channel, budget, start_date, end_date,
        expected_kpi {leads, cpl}, note, summary_report, recommended_products[].
        """
        if not self.enabled:
            return {
                "name": "Chi·∫øn d·ªãch th√°ng 10 - Facebook Ads",
                "channel": "facebook",
                "budget": 15_000_000,
                "start_date": "2025-10-01",
                "end_date": "2025-10-31",
                "expected_kpi": {"leads": 2000, "cpl": 15000},
                "note": "T·∫≠p trung remarketing nh√≥m kh√°ch h√†ng n·ªØ y√™u th√≠ch serum d∆∞·ª°ng tr·∫Øng.",
                "summary_report": "Chi·∫øn d·ªãch nh·∫±m tƒÉng 25% ƒë∆°n h√†ng Serum Vitamin C qua Facebook Ads + ∆∞u ƒë√£i -20%.",
            }

        options = options or {}
        budget_min = options.get("budget_min")
        budget_max = options.get("budget_max")
        date_from = options.get("date_from")
        date_to = options.get("date_to")
        preferred_channels = options.get("preferred_channels")

        constraints: List[str] = []
        if budget_min is not None:
            constraints.append(f"- Ng√¢n s√°ch t·ªëi thi·ªÉu: {int(budget_min)} VND.")
        if budget_max is not None:
            constraints.append(f"- Ng√¢n s√°ch t·ªëi ƒëa: {int(budget_max)} VND.")
        if date_from and date_to:
            constraints.append(f"- Th·ªùi gian tri·ªÉn khai trong kho·∫£ng: {date_from} ‚Üí {date_to}.")
        if preferred_channels:
            constraints.append(f"- ∆Øu ti√™n k√™nh: {', '.join(preferred_channels)}.")

        prompt_parts: List[str] = []
        prompt_parts.append(
            "B·∫°n l√† chuy√™n gia marketing cho th∆∞∆°ng hi·ªáu m·ªπ ph·∫©m B2C.\n"
            "H√£y ƒë·ªÅ xu·∫•t **m·ªôt** chi·∫øn d·ªãch marketing chi ti·∫øt d·ª±a tr√™n d·ªØ li·ªáu d∆∞·ªõi ƒë√¢y."
        )
        if topic:
            prompt_parts.append(f" Ch·ªß ƒë·ªÅ chi·∫øn d·ªãch: {topic}")
            prompt_parts.append("D·ªØ li·ªáu kh√°ch h√†ng:")
            prompt_parts.append(json.dumps(customer_data, ensure_ascii=False, indent=2))
        if product_data:
            prompt_parts.append("D·ªØ li·ªáu s·∫£n ph·∫©m:")
            prompt_parts.append(json.dumps(product_data, ensure_ascii=False, indent=2))
        if constraints:
            prompt_parts.append("R√†ng bu·ªôc:")
            prompt_parts.extend(constraints)
        schema_example = {
            "name": "<t√™n chi·∫øn d·ªãch>",
            "channel": "<facebook|tiktok|instagram|email|zalo|google_ads>",
            "budget": 15000000,
            "start_date": "2025-10-01",
            "end_date": "2025-10-31",
            "expected_kpi": {"leads": 2000, "cpl": 15000},
            "note": "<ghi ch√∫ ng·∫Øn g·ªçn>",
            "summary_report": "<t√≥m t·∫Øt 2-4 c√¢u>",
            "recommended_products": [
                {
                    "product_id": "<ID trong product_data>",  
                    "name": "<t√™n ƒë√∫ng trong product_data>", 
                    "category": "<lo·∫°i ƒë√∫ng trong product_data>",  
                    "price_current": 249000,
                    "reason": "<l√Ω do ng·∫Øn>",
                }
            ],
            "target_filter": {
                "gender": "female",
                 "age": {
                "max": 40,
                "min": 18},
                "interests": ["serum", "d∆∞·ª°ng ·∫©m"],
                "note": "‚Ä¶",
            },
            "data_source": "Products",
        }

        prompt_parts.append(
            "QUY T·∫ÆC R·∫§T QUAN TR·ªåNG:\n"
            "- recommended_products CH·ªà ƒë∆∞·ª£c l·∫•y t·ª´ danh s√°ch product_data cung c·∫•p.\n"
            "- Ph·∫£i ƒëi·ªÅn ƒë√∫ng product_id v√† name kh·ªõp trong product_data. N·∫øu kh√¥ng ch·∫Øc, b·ªè qua.\n"
            "- Kh√¥ng ph√°t minh t√™n s·∫£n ph·∫©m m·ªõi, kh√¥ng t·ª± t·∫°o g√≥i qu√† t·∫∑ng.\n"
        )
        prompt_parts.append(
            "Y√äU C·∫¶U XU·∫§T RA:\n"
            "- Tr·∫£ v·ªÅ **DUY NH·∫§T M·ªòT** ƒë·ªëi t∆∞·ª£ng JSON **h·ª£p l·ªá** theo c·∫•u tr√∫c **ch√≠nh x√°c** sau.\n"
            "- Kh√¥ng th√™m b·∫•t k·ª≥ vƒÉn b·∫£n n√†o ngo√†i JSON."
        )
        prompt_parts.append(json.dumps(schema_example, ensure_ascii=False, indent=2))
        prompt_parts.append("‚ö†Ô∏è Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá. Kh√¥ng th√™m b·∫•t c·ª© th·ª© g√¨ kh√°c ngo√†i JSON.")
        prompt = "\n\n".join(prompt_parts)

        # ---- LLM call & parse ----
        raw = await self._generate(prompt, model=getattr(config, "GEMINI_MODEL_GENERIC", self.model_scoring))
        data: Dict[str, Any] = _parse_json_only(raw) or {}

        # ---- Validate & normalize ----
        # Chu·∫©n ho√° tr∆∞·ªùng c∆° b·∫£n
        data["name"] = data.get("name") or "Chi·∫øn d·ªãch t·ª± ƒë·ªông"
        data["channel"] = (data.get("channel") or "facebook").lower().strip()
        data["budget"] = int(data.get("budget") or (budget_min or 10_000_000))
        data["start_date"] = data.get("start_date") or (date_from or "2025-10-01")
        data["end_date"] = data.get("end_date") or (date_to or "2025-10-31")
        data["expected_kpi"] = data.get("expected_kpi") or {"leads": 1000, "cpl": 10000}
        data["note"] = data.get("note") or ""
        data["summary_report"] = data.get("summary_report") or (raw or "")[:300]
        data["data_source"] = data.get("data_source") or "Products"
        if "target_filter" not in data or not isinstance(data["target_filter"], dict):
            data["target_filter"] = {"note": topic or "Ch∆∞a x√°c ƒë·ªãnh"}

        recommended = data.get("recommended_products")
        if product_data and isinstance(recommended, list):
            id_map = {str(p.get("product_id")): p for p in product_data if p.get("product_id")}
            name_map = {str(p.get("name", "")).strip().lower(): p for p in product_data if p.get("name")}
            validated: List[Dict[str, Any]] = []
            seen_ids: set = set()

            for rp in recommended:
                if not isinstance(rp, dict):
                    continue

                pid = rp.get("product_id")
                pname_norm = str(rp.get("name", "")).strip().lower()

                src = id_map.get(str(pid)) if pid is not None else None
                if src is None and pname_norm:
                    src = name_map.get(pname_norm)
                if not src:
                    continue  
                fixed = {
                    "product_id": src.get("product_id"),
                    "name": src.get("name"),
                    "category": src.get("category"),
                    "price_current": rp.get("price_current") or src.get("price_current"),
                    "reason": rp.get("reason") or "ƒê∆∞·ª£c ch·ªçn t·ª´ catalog do ph√π h·ª£p campaign.",
                }

                if fixed["product_id"] in seen_ids:
                    continue
                seen_ids.add(fixed["product_id"])
                validated.append(fixed)
            data["recommended_products"] = validated
        if product_data and not data.get("recommended_products"):
            def score(p: Dict[str, Any]) -> tuple:
                disc = float(p.get("discount_percent") or 0)
                rating = float(p.get("rating") or 0)
                return (disc, rating, -(float(p.get("price_current") or 0)))
            top_n = sorted(product_data, key=score, reverse=True)[:3]
            data["recommended_products"] = [
                {
                    "product_id": p.get("product_id"),
                    "name": p.get("name"),
                    "category": p.get("category"),
                    "price_current": p.get("price_current"),
                    "reason": "Ch·ªçn t·ª´ catalog theo ∆∞u ƒë√£i/ƒë√°nh gi√° cao.",
                }
                for p in top_n
            ]
        return data

    # ----------------- Expected Value -----------------
    async def predict_lead_expected_value(
        self,
        lead: Dict[str, Any],
        interested_products: List[Dict[str, Any]],
        interactions: Optional[List[Dict[str, Any]]] = None,
        options: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """D·ª± ƒëo√°n t·ªïng gi√° tr·ªã k·ª≥ v·ªçng (EV) m√† lead s·∫Ω mang l·∫°i d·ª±a tr√™n s·∫£n ph·∫©m quan t√¢m."""
        options = options or {}
        currency = options.get("currency", "VND")
        horizon_days = int(options.get("horizon_days", 30))
        repeat_rate = float(options.get("repeat_rate", 0.10))
        min_interest_score = float(options.get("min_interest_score", 0.0))
        optimize_for = options.get("optimize_for", "revenue")

        # --------- FALLBACK (Rule-based) ---------
        if not self.enabled:
            return _rule_based_ev(
                lead=lead,
                interested_products=interested_products,
                interactions=interactions,
                currency=currency,
                horizon_days=horizon_days,
                repeat_rate=repeat_rate,
                min_interest_score=min_interest_score,
                optimize_for=optimize_for,
            )

        # --------- LLM MODE ----------
        constraints = [
            f"- Ti·ªÅn t·ªá: {currency}",
            f"- Horizon d·ª± b√°o (ng√†y): {horizon_days}",
            f"- Repeat rate: {repeat_rate}",
            f"- L·ªçc s·∫£n ph·∫©m c√≥ interest_score >= {min_interest_score}",
            f"- T·ªëi ∆∞u theo: {optimize_for}",
        ]

        prompt_parts: List[str] = []
        prompt_parts.append(
            "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch doanh thu. H√£y ∆∞·ªõc t√≠nh **gi√° tr·ªã k·ª≥ v·ªçng** (expected value) m·ªôt lead mang l·∫°i "
            "trong kho·∫£ng th·ªùi gian ch·ªâ ƒë·ªãnh, d·ª±a tr√™n s·∫£n ph·∫©m m√† lead quan t√¢m. Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá."
        )
        prompt_parts.append("üìá Lead:")
        prompt_parts.append(json.dumps(lead, ensure_ascii=False, indent=2))
        if interactions:
            prompt_parts.append("üóíÔ∏è Interactions g·∫ßn ƒë√¢y:")
            prompt_parts.append(json.dumps(interactions, ensure_ascii=False, indent=2))
        prompt_parts.append("üõçÔ∏è S·∫£n ph·∫©m quan t√¢m:")
        prompt_parts.append(json.dumps(interested_products, ensure_ascii=False, indent=2))
        prompt_parts.append("R√†ng bu·ªôc & tham s·ªë:")
        prompt_parts.extend(constraints)

        schema_example = {
            "lead_id": "<uuid>",
            "currency": "VND",
            "horizon_days": 30,
            "assumptions": {
                "base_conversion_prob": 0.18,
                "repeat_rate": 0.15,
                "min_interest_score": 0.2,
                "optimize_for": "revenue",
            },
            "breakdown": [
                {
                    "product_id": "<id>",
                    "name": "<t√™n>",
                    "price": 390000,
                    "base_prob": 0.15,
                    "adjusted_prob": 0.21,
                    "expected_orders": 1.1,
                    "expected_value": 429000.0,
                    "expected_margin": 171600.0,
                    "reason": "<ng·∫Øn g·ªçn>",
                }
            ],
            "expected_total_value": 1200000.0,
            "expected_total_margin": 520000.0,
            "generated_at": "2025-10-25T02:20:00Z",
            "note": "EV = price * adjusted_prob * (1 + repeat_rate)",
        }

        prompt_parts.append(
            "Y√äU C·∫¶U XU·∫§T RA:\n"
            "- Ch·ªâ tr·∫£ v·ªÅ M·ªòT ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá theo c·∫•u tr√∫c m·∫´u d∆∞·ªõi ƒë√¢y (c√≥ th·ªÉ thay s·ªë li·ªáu).\n"
            "- Kh√¥ng th√™m text ngo√†i JSON, kh√¥ng markdown."
        )
        prompt_parts.append(json.dumps(schema_example, ensure_ascii=False, indent=2))
        prompt = "\n\n".join(prompt_parts)

        raw = await self._generate(prompt, model=getattr(config, "GEMINI_MODEL_GENERIC", self.model_scoring))
        data = _parse_json_only(raw)
        if isinstance(data, dict):
            return data

        # Fallback cu·ªëi c√πng -> quay v·ªÅ rule-based
        self.enabled = False
        return await self.predict_lead_expected_value(lead, interested_products, interactions, options)

    # ----------------- Core Gemini Call -----------------
    async def _generate(self, prompt: str, model: str) -> str:
        """
        G·ªçi t·ªõi API Gemini ƒë·ªÉ sinh n·ªôi dung.
        Tr·∫£ v·ªÅ chu·ªói (c√≥ th·ªÉ l√† JSON ho·∫∑c c√≥ l·∫´n text).
        """
        if not self.enabled:
            return ""

        def _call() -> str:
            gen_model = genai.GenerativeModel(model)  # type: ignore
            response = gen_model.generate_content(prompt)
            if hasattr(response, "text") and response.text:
                return str(response.text).strip()
            if hasattr(response, "candidates") and response.candidates:
                part0 = response.candidates[0].content.parts[0]
                return getattr(part0, "text", "") or ""
            return ""

        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, _call)


# ==============================
# Helpers
# ==============================
def _parse_json_only(raw: Optional[str]) -> Optional[Dict[str, Any]]:
    """
    C·ªë g·∫Øng parse JSON h·ª£p l·ªá t·ª´ chu·ªói raw (c√≥ th·ªÉ l·∫´n text).
    Ch·ªâ tr·∫£ v·ªÅ dict n·∫øu parse th√†nh c√¥ng, ng∆∞·ª£c l·∫°i tr·∫£ None.
    """
    if not raw:
        return None
    raw = raw.strip()
    # Th·ª≠ parse tr·ª±c ti·∫øp
    try:
        data = json.loads(raw)
        if isinstance(data, dict):
            return data
    except Exception:
        pass
    # Th·ª≠ t√°ch ph·∫ßn {...}
    try:
        import re

        m = re.search(r"\{.*\}", raw, flags=re.DOTALL)
        if m:
            data = json.loads(m.group(0))
            if isinstance(data, dict):
                return data
    except Exception:
        pass
    return None


def _rule_based_ev(
    lead: Dict[str, Any],
    interested_products: List[Dict[str, Any]],
    interactions: Optional[List[Dict[str, Any]]],
    currency: str,
    horizon_days: int,
    repeat_rate: float,
    min_interest_score: float,
    optimize_for: str,
) -> Dict[str, Any]:
    """Fallback EV rule-based, t√°ch ri√™ng cho g·ªçn."""
    lead_conv = float(lead.get("conversion_prob") or 0.12)

    # Hi·ªáu ch·ªânh t·ª´ lead_score: +1% x√°c su·∫•t cho m·ªói 10 ƒëi·ªÉm, capped ¬±30%
    lead_score = float(lead.get("lead_score") or 0)
    score_factor = max(0.7, min(1.3, 1.0 + (lead_score - 50.0) / 500.0))

    # Hi·ªáu ch·ªânh t∆∞∆°ng t√°c g·∫ßn ƒë√¢y
    recency_factor = 1.0
    if interactions:
        latest_ts = None
        for it in interactions:
            t = it.get("occurred_at")
            if isinstance(t, str):
                try:
                    t = datetime.fromisoformat(t.replace("Z", "+00:00"))
                except Exception:
                    t = None
            if isinstance(t, datetime):
                latest_ts = max(latest_ts or t, t)
        if latest_ts:
            days = (datetime.now(timezone.utc) - latest_ts.astimezone(timezone.utc)).days
            if days <= 7:
                recency_factor = 1.10
            elif days <= 14:
                recency_factor = 1.05

    base_prob = max(0.01, min(0.8, lead_conv * score_factor * recency_factor))

    breakdown: List[Dict[str, Any]] = []
    total_ev = 0.0
    total_margin = 0.0

    for p in (interested_products or []):
        price = float(p.get("price") or 0)
        if price <= 0:
            continue
        interest = float(p.get("interest_score") or 0.5)
        if interest < min_interest_score:
            continue

        category = (p.get("category") or "").lower()
        cat_factor = 1.0
        if category in {"serum", "treatment"}:
            cat_factor = 1.05
        elif category in {"makeup"}:
            cat_factor = 0.95

        adjusted_prob = max(0.01, min(0.95, base_prob * (0.6 + 0.8 * interest) * cat_factor))
        expected_orders = 1.0 * adjusted_prob * (1.0 + repeat_rate)

        expected_value = price * expected_orders
        margin_rate = float(p.get("margin_rate")) if p.get("margin_rate") is not None else 0.4
        expected_margin = expected_value * margin_rate

        breakdown.append(
            {
                "product_id": p.get("product_id"),
                "name": p.get("name"),
                "price": int(price),
                "base_prob": round(base_prob, 3),
                "adjusted_prob": round(adjusted_prob, 3),
                "expected_orders": round(expected_orders, 3),
                "expected_value": round(expected_value, 2),
                "expected_margin": round(expected_margin, 2),
                "reason": f"interest={interest}, cat_factor={cat_factor}",
            }
        )

        total_ev += expected_value
        total_margin += expected_margin

    result: Dict[str, Any] = {
        "lead_id": lead.get("lead_id"),
        "currency": currency,
        "horizon_days": horizon_days,
        "assumptions": {
            "base_conversion_prob": round(base_prob, 3),
            "repeat_rate": repeat_rate,
            "min_interest_score": min_interest_score,
            "optimize_for": optimize_for,
        },
        "breakdown": breakdown,
        "expected_total_value": round(total_ev, 2),
        "generated_at": datetime.utcnow().replace(tzinfo=timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
        "note": "EV = price * adjusted_prob * (1 + repeat_rate)",
    }
    if optimize_for == "margin":
        result["expected_total_margin"] = round(total_margin, 2)
    return result
