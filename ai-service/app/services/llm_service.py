import asyncio
import json
from typing import Any, Dict, List, Optional
from app import config
from datetime import datetime, timezone
try:
    import google.generativeai as genai
    _GEMINI_AVAILABLE = True
except Exception as e:
    print("[LLM] ‚ö†Ô∏è Google GenerativeAI SDK not found:", e)
    genai = None
    _GEMINI_AVAILABLE = False


class LLMService:
    def __init__(self):
        self.enabled = bool(config.GEMINI_API_KEY and _GEMINI_AVAILABLE)
        if self.enabled:
            print("[LLM] ‚úÖ Gemini enabled with model:", config.GEMINI_MODEL_GENERIC)
            genai.configure(api_key=config.GEMINI_API_KEY)
        else:
            print("[LLM] ‚ö†Ô∏è Gemini disabled (missing API key or SDK).")

    # ----------------- Generate Email -----------------
    async def generate_email_content(
        self,
        context: Dict[str, Any],
        purpose: str = "promotion",
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, str]:
        """
        Sinh n·ªôi dung email g·ªìm {subject, body} d·ª±a tr√™n ng·ªØ c·∫£nh action.
        context c√≥ th·ªÉ g·ªìm: name, product, campaign, tone, language, offer,...
        """
        if not self.enabled:
            return {
                "subject": f"[{context.get('campaign','Th√¥ng b√°o')}] {context.get('product','S·∫£n ph·∫©m m·ªõi')} c·ªßa b·∫°n",
                "body": (
                    f"Xin ch√†o {context.get('name','b·∫°n')},\n\n"
                    f"Ch√∫ng t√¥i xin gi·ªõi thi·ªáu {context.get('product','s·∫£n ph·∫©m m·ªõi')}."
                    f" H√£y gh√© c·ª≠a h√†ng ƒë·ªÉ nh·∫≠n ∆∞u ƒë√£i {context.get('offer','ƒë·∫∑c bi·ªát')}!\n\n"
                    "Th√¢n m·∫øn,\nƒê·ªôi ng≈© chƒÉm s√≥c kh√°ch h√†ng."
                )
            }

        # prompt ch√≠nh th·ª©c
        prompt = (
            "B·∫°n l√† chuy√™n gia marketing trong lƒ©nh v·ª±c m·ªπ ph·∫©m. "
            "H√£y so·∫°n **email** b·∫±ng ti·∫øng Vi·ªát ph√π h·ª£p v·ªõi m·ª•c ƒë√≠ch d∆∞·ªõi ƒë√¢y.\n\n"
            f"- M·ª•c ƒë√≠ch: {purpose}\n"
            "- Y√™u c·∫ßu:\n"
            "  ‚Ä¢ Vi·∫øt ng·∫Øn g·ªçn, t·ª± nhi√™n, ph√π h·ª£p kh√°ch h√†ng B2C.\n"
            "  ‚Ä¢ Tr·∫£ v·ªÅ **JSON h·ª£p l·ªá** d·∫°ng:\n"
            '    {"subject": "<ti√™u ƒë·ªÅ>", "body": "<n·ªôi dung email>"}.\n'
            "  ‚Ä¢ Kh√¥ng vi·∫øt ngo√†i JSON.\n\n"
            f"Ng·ªØ c·∫£nh action:\n{json.dumps(context, ensure_ascii=False, indent=2)}"
        )

        raw = await self._generate(prompt, model=config.GEMINI_MODEL_GENERIC)

        try:
            return json.loads(raw)
        except Exception:
            subj = f"Khuy·∫øn m√£i: {context.get('product','S·∫£n ph·∫©m m·ªõi')} ƒëang gi·∫£m gi√°!"
            return {"subject": subj, "body": raw.strip()[:1000]}
    async def suggest_marketing_campaign(
        self,
        customer_data: List[Dict[str, Any]],
        product_data: Optional[List[Dict[str, Any]]] = None,
        topic: Optional[str] = None,
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ƒê·ªÅ xu·∫•t 1 chi·∫øn d·ªãch marketing chi ti·∫øt (JSON h·ª£p l·ªá).
        Tr·∫£ v·ªÅ dict c√≥ c√°c tr∆∞·ªùng: name, channel, budget, start_date, end_date,
        expected_kpi {leads, cpl}, note, summary_report.
        """
        # Fallback khi Gemini ch∆∞a s·∫µn s√†ng
        if not self.enabled:
            return {
                "name": "Chi·∫øn d·ªãch th√°ng 10 - Facebook Ads",
                "channel": "facebook",
                "budget": 15_000_000,
                "start_date": "2025-10-01",
                "end_date": "2025-10-31",
                "expected_kpi": {"leads": 2000, "cpl": 15000},
                "note": "T·∫≠p trung remarketing nh√≥m kh√°ch h√†ng n·ªØ y√™u th√≠ch serum d∆∞·ª°ng tr·∫Øng.",
                "summary_report": "Chi·∫øn d·ªãch nh·∫±m tƒÉng 25% ƒë∆°n h√†ng Serum Vitamin C qua Facebook Ads + ∆∞u ƒë√£i -20%.",
            }

        options = options or {}
        budget_min = options.get("budget_min")
        budget_max = options.get("budget_max")
        date_from  = options.get("date_from")   # "YYYY-MM-DD"
        date_to    = options.get("date_to")     # "YYYY-MM-DD"
        preferred_channels = options.get("preferred_channels")  # e.g. ["facebook","tiktok","email"]

        constraints = []
        if budget_min is not None:
            constraints.append(f"- Ng√¢n s√°ch t·ªëi thi·ªÉu: {int(budget_min)} VND.")
        if budget_max is not None:
            constraints.append(f"- Ng√¢n s√°ch t·ªëi ƒëa: {int(budget_max)} VND.")
        if date_from and date_to:
            constraints.append(f"- Th·ªùi gian tri·ªÉn khai trong kho·∫£ng: {date_from} ‚Üí {date_to}.")
        if preferred_channels:
            constraints.append(f"- ∆Øu ti√™n k√™nh: {', '.join(preferred_channels)}.")

        # X√¢y prompt ch·∫∑t ch·∫Ω
        prompt_parts = []
        prompt_parts.append(
            "B·∫°n l√† chuy√™n gia marketing cho th∆∞∆°ng hi·ªáu m·ªπ ph·∫©m B2C.\n"
            "H√£y ƒë·ªÅ xu·∫•t **m·ªôt** chi·∫øn d·ªãch marketing chi ti·∫øt d·ª±a tr√™n d·ªØ li·ªáu d∆∞·ªõi ƒë√¢y. D·ª± ƒëo√°n k√™nh s·∫Ω ƒë∆∞·ª£c quan t√¢m nh·∫•t v√† d·ª±a tr√™n c√°c xu h∆∞·ªõng hi·ªán t·∫°i tr√™n th·ªã tr∆∞·ªùng"
        )
        if topic:
            prompt_parts.append(f"üéØ Ch·ªß ƒë·ªÅ chi·∫øn d·ªãch: {topic}")

        prompt_parts.append("üìä D·ªØ li·ªáu kh√°ch h√†ng:")
        prompt_parts.append(json.dumps(customer_data, ensure_ascii=False, indent=2))

        if product_data:
            prompt_parts.append("üõçÔ∏è D·ªØ li·ªáu s·∫£n ph·∫©m:")
            prompt_parts.append(json.dumps(product_data, ensure_ascii=False, indent=2))

        if constraints:
            prompt_parts.append("R√†ng bu·ªôc:")
            prompt_parts.extend(constraints)

        prompt_parts.append(
            "Y√äU C·∫¶U XU·∫§T RA:\n"
            "- Tr·∫£ v·ªÅ **DUY NH·∫§T M·ªòT** ƒë·ªëi t∆∞·ª£ng JSON **h·ª£p l·ªá** theo c·∫•u tr√∫c **ch√≠nh x√°c** sau.\n"
            "- Kh√¥ng th√™m b·∫•t k·ª≥ vƒÉn b·∫£n n√†o ngo√†i JSON (kh√¥ng preface, kh√¥ng gi·∫£i th√≠ch, kh√¥ng Markdown).\n"
            "- D√πng d·∫•u ngo·∫∑c k√©p ƒë√¥i cho t·∫•t c·∫£ kh√≥a/chu·ªói; ng√†y theo ƒë·ªãnh d·∫°ng ISO (YYYY-MM-DD);\n"
            "  c√°c tr∆∞·ªùng s·ªë ti·ªÅn (budget, cpl) l√† s·ªë nguy√™n VND (kh√¥ng d·∫•u ph·∫©y, kh√¥ng k√Ω t·ª±)."
        )

        schema_example = {
            "name": "<t√™n chi·∫øn d·ªãch>",
            "channel": "<k√™nh qu·∫£ng c√°o: facebook | tiktok | instagram | email | zalo | google_ads>",
            "budget": 15000000,
            "start_date": "2025-10-01",
            "end_date": "2025-10-31",
            "expected_kpi": {"leads": 2000, "cpl": 15000},
            "note": "<ghi ch√∫ ng·∫Øn g·ªçn, 1-2 c√¢u>",
            "summary_report": "<t√≥m t·∫Øt 2-4 c√¢u v·ªÅ m·ª•c ti√™u & c√°ch tri·ªÉn khai v√† li·ªát k√™ c√°c s·∫£n ph·∫©m n√™n ƒë∆∞·ª£c ch·∫°y trong chi·∫øn d·ªãch>",
            "recommended_products": [
                    {
                        "name": "<t√™n s·∫£n ph·∫©m>",
                        "category": "<lo·∫°i s·∫£n ph·∫©m>",
                        "reason": "<l√Ω do ƒë∆∞·ª£c ch·ªçn>"
                    }
        ]
        }
        prompt_parts.append("C·∫•u tr√∫c JSON b·∫Øt bu·ªôc (ch·ªâ l√† v√≠ d·ª• c·∫•u tr√∫c, kh√¥ng c·∫ßn l·∫∑p l·∫°i vƒÉn b·∫£n n√†y):")
        prompt_parts.append(json.dumps(schema_example, ensure_ascii=False, indent=2))

        prompt_parts.append("‚ö†Ô∏è Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá. Kh√¥ng th√™m b·∫•t c·ª© th·ª© g√¨ kh√°c ngo√†i JSON.")

        prompt = "\n\n".join(prompt_parts)

        raw = await self._generate(prompt, model=config.GEMINI_MODEL_GENERIC)

        # Parse JSON an to√†n
        try:
            return json.loads(raw)
        except Exception:
            # Th·ª≠ t√°ch JSON n·∫øu model l·ª° k√®m text (ph√≤ng h·ªù)
            import re
            m = re.search(r"\{.*\}", raw, flags=re.DOTALL)
            if m:
                try:
                    return json.loads(m.group(0))
                except Exception:
                    pass
            # Fallback cu·ªëi
            return {
                "name": "Chi·∫øn d·ªãch t·ª± ƒë·ªông",
                "channel": (preferred_channels[0] if isinstance(preferred_channels, list) and preferred_channels else "facebook"),
                "budget": int(budget_min) if isinstance(budget_min, (int, float)) else 10_000_000,
                "start_date": date_from or "2025-10-01",
                "end_date": date_to or "2025-10-31",
                "expected_kpi": {"leads": 1000, "cpl": 10000},
                "note": "AI tr·∫£ v·ªÅ text kh√¥ng h·ª£p l·ªá, d√πng fallback theo r√†ng bu·ªôc.",
                "summary_report": (raw or "")[:300]
            }
    async def predict_lead_expected_value(
        self,
        lead: Dict[str, Any],
        interested_products: List[Dict[str, Any]],
        interactions: Optional[List[Dict[str, Any]]] = None,
        options: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        D·ª± ƒëo√°n t·ªïng gi√° tr·ªã k·ª≥ v·ªçng (EV) m√† lead s·∫Ω mang l·∫°i d·ª±a tr√™n s·∫£n ph·∫©m quan t√¢m.
        """
        options = options or {}
        currency = options.get("currency", "VND")
        horizon_days = int(options.get("horizon_days", 30))
        repeat_rate = float(options.get("repeat_rate", 0.10))
        min_interest_score = float(options.get("min_interest_score", 0.0))
        optimize_for = options.get("optimize_for", "revenue")  # ho·∫∑c "margin"

        # --------- FALLBACK (Rule-based) ---------
        if not self.enabled:
            lead_conv = float(lead.get("conversion_prob") or 0.12)

            # Hi·ªáu ch·ªânh t·ª´ lead_score (n·∫øu c√≥): +1% x√°c su·∫•t cho m·ªói 10 ƒëi·ªÉm, capped ¬±30%
            lead_score = float(lead.get("lead_score") or 0)
            score_factor = max(0.7, min(1.3, 1.0 + (lead_score - 50.0) / 500.0))

            # Hi·ªáu ch·ªânh t∆∞∆°ng t√°c g·∫ßn ƒë√¢y (n·∫øu c√≥)
            recency_factor = 1.0
            if interactions:
                latest_ts = None
                for it in interactions:
                    t = it.get("occurred_at")
                    if isinstance(t, str):
                        try:
                            t = datetime.fromisoformat(t.replace("Z", "+00:00"))
                        except Exception:
                            t = None
                    if isinstance(t, datetime):
                        latest_ts = max(latest_ts or t, t)
                if latest_ts:
                    days = (datetime.now(timezone.utc) - latest_ts.astimezone(timezone.utc)).days
                    if days <= 7:
                        recency_factor = 1.10
                    elif days <= 14:
                        recency_factor = 1.05

            base_prob = max(0.01, min(0.8, lead_conv * score_factor * recency_factor))

            breakdown = []
            total_ev = 0.0
            total_margin = 0.0

            for p in (interested_products or []):
                price = float(p.get("price") or 0)
                if price <= 0:
                    continue
                interest = float(p.get("interest_score") or 0.5)
                if interest < min_interest_score:
                    continue

                category = (p.get("category") or "").lower()
                cat_factor = 1.0
                if category in {"serum", "treatment"}:
                    cat_factor = 1.05
                elif category in {"makeup"}:
                    cat_factor = 0.95

                adjusted_prob = max(0.01, min(0.95, base_prob * (0.6 + 0.8 * interest) * cat_factor))

                expected_orders = 1.0 * adjusted_prob * (1.0 + repeat_rate)

                expected_value = price * expected_orders
                margin_rate = float(p.get("margin_rate")) if p.get("margin_rate") is not None else 0.4
                expected_margin = expected_value * margin_rate

                breakdown.append({
                    "product_id": p.get("product_id"),
                    "name": p.get("name"),
                    "price": int(price),
                    "base_prob": round(base_prob, 3),
                    "adjusted_prob": round(adjusted_prob, 3),
                    "expected_orders": round(expected_orders, 3),
                    "expected_value": round(expected_value, 2),
                    "expected_margin": round(expected_margin, 2),
                    "reason": f"interest={interest}, cat_factor={cat_factor}"
                })

                total_ev += expected_value
                total_margin += expected_margin

            result: Dict[str, Any] = {
                "lead_id": lead.get("lead_id"),
                "currency": currency,
                "horizon_days": horizon_days,
                "assumptions": {
                    "base_conversion_prob": round(base_prob, 3),
                    "repeat_rate": repeat_rate,
                    "min_interest_score": min_interest_score,
                    "optimize_for": optimize_for
                },
                "breakdown": breakdown,
                "expected_total_value": round(total_ev, 2),
                "generated_at": datetime.utcnow().replace(tzinfo=timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
                "note": "EV = price * adjusted_prob * (1 + repeat_rate)"
            }
            if optimize_for == "margin":
                result["expected_total_margin"] = round(total_margin, 2)
            return result

        # --------- LLM MODE (self.enabled=True) ----------
        constraints = [
            f'- Ti·ªÅn t·ªá: {currency}',
            f'- Horizon d·ª± b√°o (ng√†y): {horizon_days}',
            f'- Repeat rate: {repeat_rate}',
            f'- L·ªçc s·∫£n ph·∫©m c√≥ interest_score >= {min_interest_score}',
            f'- T·ªëi ∆∞u theo: {optimize_for}',
        ]

        prompt_parts = []
        prompt_parts.append(
            "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch doanh thu. H√£y ∆∞·ªõc t√≠nh **gi√° tr·ªã k·ª≥ v·ªçng** (expected value) m·ªôt lead mang l·∫°i "
            "trong kho·∫£ng th·ªùi gian ch·ªâ ƒë·ªãnh, d·ª±a tr√™n s·∫£n ph·∫©m m√† lead quan t√¢m. Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá."
        )
        prompt_parts.append("üìá Lead:")
        prompt_parts.append(json.dumps(lead, ensure_ascii=False, indent=2))
        if interactions:
            prompt_parts.append("üóíÔ∏è Interactions g·∫ßn ƒë√¢y:")
            prompt_parts.append(json.dumps(interactions, ensure_ascii=False, indent=2))
        prompt_parts.append("üõçÔ∏è S·∫£n ph·∫©m quan t√¢m:")
        prompt_parts.append(json.dumps(interested_products, ensure_ascii=False, indent=2))
        prompt_parts.append("R√†ng bu·ªôc & tham s·ªë:")
        prompt_parts.extend(constraints)

        schema_example = {
            "lead_id": "<uuid>",
            "currency": "VND",
            "horizon_days": 30,
            "assumptions": {
                "base_conversion_prob": 0.18,
                "repeat_rate": 0.15,
                "min_interest_score": 0.2,
                "optimize_for": "revenue"
            },
            "breakdown": [
                {
                    "product_id": "<id>",
                    "name": "<t√™n>",
                    "price": 390000,
                    "base_prob": 0.15,
                    "adjusted_prob": 0.21,
                    "expected_orders": 1.1,
                    "expected_value": 429000.0,
                    "expected_margin": 171600.0,
                    "reason": "<ng·∫Øn g·ªçn>"
                }
            ],
            "expected_total_value": 1200000.0,
            "expected_total_margin": 520000.0,
            "generated_at": "2025-10-25T02:20:00Z",
            "note": "EV = price * adjusted_prob * (1 + repeat_rate)"
        }

        prompt_parts.append(
            "Y√äU C·∫¶U XU·∫§T RA:\n"
            "- Ch·ªâ tr·∫£ v·ªÅ M·ªòT ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá theo c·∫•u tr√∫c m·∫´u d∆∞·ªõi ƒë√¢y (c√≥ th·ªÉ thay s·ªë li·ªáu).\n"
            "- Kh√¥ng th√™m text ngo√†i JSON, kh√¥ng markdown."
        )
        prompt_parts.append(json.dumps(schema_example, ensure_ascii=False, indent=2))
        prompt = "\n\n".join(prompt_parts)

        raw = await self._generate(prompt, model=getattr(config, "GEMINI_MODEL_GENERIC", "gemini-1.5-flash"))

        try:
            return json.loads(raw)
        except Exception:
            import re
            m = re.search(r"\{.*\}", raw or "", flags=re.DOTALL)
            if m:
                try:
                    return json.loads(m.group(0))
                except Exception:
                    pass
            # Fallback cu·ªëi (n·∫øu LLM tr·∫£ v·ªÅ kh√¥ng h·ª£p l·ªá): g·ªçi l·∫°i ch√≠nh nh√°nh rule-based
            self.enabled = False
            return await self.predict_lead_expected_value(
                lead, interested_products, interactions, options
            )

        # --------- LLM MODE (self.enabled=True) ----------
        constraints = []
        constraints.append(f'- Ti·ªÅn t·ªá: {currency}')
        constraints.append(f'- Horizon d·ª± b√°o (ng√†y): {horizon_days}')
        constraints.append(f'- Repeat rate: {repeat_rate}')
        constraints.append(f'- L·ªçc s·∫£n ph·∫©m c√≥ interest_score >= {min_interest_score}')
        constraints.append(f'- T·ªëi ∆∞u theo: {optimize_for}')

        prompt_parts = []
        prompt_parts.append(
            "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch doanh thu. H√£y ∆∞·ªõc t√≠nh **gi√° tr·ªã k·ª≥ v·ªçng** (expected value) m·ªôt lead mang l·∫°i "
            "trong kho·∫£ng th·ªùi gian ch·ªâ ƒë·ªãnh, d·ª±a tr√™n s·∫£n ph·∫©m m√† lead quan t√¢m. Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá."
        )
        prompt_parts.append("üìá Lead:")
        prompt_parts.append(json.dumps(lead, ensure_ascii=False, indent=2))
        if interactions:
            prompt_parts.append("üóíÔ∏è Interactions g·∫ßn ƒë√¢y:")
            prompt_parts.append(json.dumps(interactions, ensure_ascii=False, indent=2))
        prompt_parts.append("üõçÔ∏è S·∫£n ph·∫©m quan t√¢m:")
        prompt_parts.append(json.dumps(interested_products, ensure_ascii=False, indent=2))
        prompt_parts.append("R√†ng bu·ªôc & tham s·ªë:")
        prompt_parts.extend(constraints)

        schema_example = {
            "lead_id": "<uuid>",
            "currency": "VND",
            "horizon_days": 30,
            "assumptions": {
                "base_conversion_prob": 0.18,
                "repeat_rate": 0.15,
                "min_interest_score": 0.2,
                "optimize_for": "revenue"
            },
            "breakdown": [
                {
                    "product_id": "<id>",
                    "name": "<t√™n>",
                    "price": 390000,
                    "base_prob": 0.15,
                    "adjusted_prob": 0.21,
                    "expected_orders": 1.1,
                    "expected_value": 429000.0,
                    "expected_margin": 171600.0,
                    "reason": "<ng·∫Øn g·ªçn>"
                }
            ],
            "expected_total_value": 1200000.0,
            "expected_total_margin": 520000.0,
            "generated_at": "2025-10-25T02:20:00Z",
            "note": "EV = price * adjusted_prob * (1 + repeat_rate)"
        }

        prompt_parts.append(
            "Y√äU C·∫¶U XU·∫§T RA:\n"
            "- Ch·ªâ tr·∫£ v·ªÅ M·ªòT ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá theo c·∫•u tr√∫c m·∫´u d∆∞·ªõi ƒë√¢y (c√≥ th·ªÉ thay s·ªë li·ªáu).\n"
            "- Kh√¥ng th√™m text ngo√†i JSON, kh√¥ng markdown."
        )
        prompt_parts.append(json.dumps(schema_example, ensure_ascii=False, indent=2))
        prompt = "\n\n".join(prompt_parts)

        raw = await self._generate(prompt, model="your-generic-llm-id")

        try:
            return json.loads(raw)
        except Exception:
            import re
            m = re.search(r"\{.*\}", raw, flags=re.DOTALL)
            if m:
                try:
                    return json.loads(m.group(0))
                except Exception:
                    pass
            # Fallback cu·ªëi (n·∫øu LLM tr·∫£ v·ªÅ kh√¥ng h·ª£p l·ªá): g·ªçi l·∫°i ch√≠nh nh√°nh rule-based
            self.enabled = False
            return await self.predict_lead_expected_value(
                lead, interested_products, interactions, options
            )
        
    # ----------------- Core Gemini Call -----------------
    async def _generate(self, prompt: str, model: str) -> str:
        """
        G·ªçi t·ªõi API Gemini ƒë·ªÉ sinh n·ªôi dung.
        """
        if not self.enabled:
            return ""

        def _call():
            gen_model = genai.GenerativeModel(model)
            response = gen_model.generate_content(prompt)
            if hasattr(response, "text") and response.text:
                return response.text.strip()
            elif hasattr(response, "candidates") and response.candidates:
                return response.candidates[0].content.parts[0].text
            else:
                return ""
        return await asyncio.get_event_loop().run_in_executor(None, _call)
