{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52980423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded: data_raw\\google (1).csv - 175 rows\n",
      "‚úÖ Loaded: data_raw\\google (10).csv - 243 rows\n",
      "‚úÖ Loaded: data_raw\\google (11).csv - 5612 rows\n",
      "‚úÖ Loaded: data_raw\\google (12).csv - 4412 rows\n",
      "‚úÖ Loaded: data_raw\\google (2).csv - 236 rows\n",
      "‚úÖ Loaded: data_raw\\google (3).csv - 126 rows\n",
      "‚úÖ Loaded: data_raw\\google (4).csv - 55 rows\n",
      "‚úÖ Loaded: data_raw\\google (5).csv - 209 rows\n",
      "‚úÖ Loaded: data_raw\\google (6).csv - 209 rows\n",
      "‚úÖ Loaded: data_raw\\google (7).csv - 727 rows\n",
      "‚úÖ Loaded: data_raw\\google (8).csv - 2715 rows\n",
      "‚úÖ Loaded: data_raw\\google (9).csv - 16 rows\n",
      "\n",
      "üéâ Merged 12 files -> merged_restaurants.csv (14735 rows)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# üìÅ Th∆∞ m·ª•c ch·ª©a c√°c file d·ªØ li·ªáu\n",
    "input_dir = \"data_raw\"      # ƒë·ªïi l·∫°i ƒë√∫ng th∆∞ m·ª•c b·∫°n ƒë·ªÉ file\n",
    "output_file = \"merged_restaurants.csv\"\n",
    "\n",
    "# üß© L·∫•y danh s√°ch t·∫•t c·∫£ file .csv ho·∫∑c .tsv\n",
    "files = glob.glob(os.path.join(input_dir, \"*.csv\")) + glob.glob(os.path.join(input_dir, \"*.tsv\"))\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for f in files:\n",
    "    try:\n",
    "        # Auto detect delimiter (v√¨ Google export c√≥ th·ªÉ \",\" ho·∫∑c tab)\n",
    "        df = pd.read_csv(f, sep=None, engine='python', on_bad_lines='skip')\n",
    "        df[\"source_file\"] = os.path.basename(f)   # th√™m c·ªôt ngu·ªìn ƒë·ªÉ trace d·ªØ li·ªáu\n",
    "        all_dfs.append(df)\n",
    "        print(f\"‚úÖ Loaded: {f} - {len(df)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {f}: {e}\")\n",
    "\n",
    "# üìä G·ªôp t·∫•t c·∫£ file\n",
    "if all_dfs:\n",
    "    merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    # üßπ L√†m s·∫°ch: b·ªè h√†ng r·ªóng ho√†n to√†n\n",
    "    merged_df.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "    # üßæ Chu·∫©n t√™n c·ªôt (lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, vi·∫øt th∆∞·ªùng)\n",
    "    merged_df.columns = [\n",
    "        c.strip().lower().replace(\" \", \"_\").replace(\".\", \"\").replace(\"-\", \"_\")\n",
    "        for c in merged_df.columns\n",
    "    ]\n",
    "\n",
    "    # üß© B·ªè c·ªôt tr√πng\n",
    "    merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
    "\n",
    "    # üíæ Xu·∫•t ra CSV\n",
    "    merged_df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nüéâ Merged {len(files)} files -> {output_file} ({len(merged_df)} rows)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c load.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1509bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ tr√≠ch xu·∫•t 12271 link v√†o: href_links.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === ƒê∆Ø·ªúNG D·∫™N FILE NGU·ªíN ===\n",
    "input_file = \"merged_data.csv\"      # File g·ªëc b·∫°n ƒë√£ g·ªôp\n",
    "output_file = \"href_links.csv\"      # File xu·∫•t ch·ªâ ch·ª©a link\n",
    "\n",
    "# === ƒê·ªåC FILE G·ªêC ===\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# === KI·ªÇM TRA C·ªòT ===\n",
    "target_col = None\n",
    "for col in df.columns:\n",
    "    if col.lower() in [\"hfpxzc_href\", \"href\", \"link\"]:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col is None:\n",
    "    print(\"‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt hfpxzc_href ho·∫∑c href trong file!\")\n",
    "else:\n",
    "    # === L·∫§Y C·ªòT V√Ä LO·∫†I GI√Å TR·ªä R·ªñNG ===\n",
    "    href_df = df[[target_col]].dropna().drop_duplicates()\n",
    "    href_df.columns = [\"Link\"]  # ƒê·ªïi t√™n c·ªôt cho ƒë·∫πp\n",
    "\n",
    "    # === XU·∫§T RA FILE M·ªöI ===\n",
    "    href_df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"‚úÖ ƒê√£ tr√≠ch xu·∫•t {len(href_df)} link v√†o: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
